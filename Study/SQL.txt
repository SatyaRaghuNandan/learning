Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2017-01-12T12:54:52+00:00

====== SQL ======
Created Thursday 12 January 2017

PostgreSQL performance:
	http://okigiveup.net/what-postgresql-tells-you-about-its-performance/
	
High-Performance Blog:
	https://www.periscopedata.com/blog/interactive-analytics-redshift-bigquery-snowflake.html
	
Example of Clean Code:
	http://jonathansacramento.com/posts/20161119_clean_sql.html#
	
AWS Redshift:
	performance deep dive: https://www.youtube.com/watch?v=fmy3jCxUliM
	2016 what's new: https://www.youtube.com/watch?v=OyHhYIUEPQ4
	

**To Learn:**
	MySQL, Oracle, RedShift
	Cloud Analytics solution: AWS RedShift
	
**Topics:**
	partition key
	
	Best Practices for Query Optimization
		Execution Plan
			Use EXPLAIN keyword to see the execution plan for the query:
				check the index usage
				check rows scanned
		Try to Convert <> operator to = operator (which increases the chance for indices to be used)
		Avoid using SELECT * (unless it's necessary)
			Forces full table scan (ignores the indices)
			Waste network bandwidth
		Split big DELETE, UPDATE or INSERT query into multiple smaller queries
			  Better performance, better control over data movement
		**MySQL query cache is case and space sensitive**
			**Use same query case for repeat queries**
		Index columns in the WHERE clause
		Index columns used in JOIN
		Index columns used in ORDER BY
		Use UNION ALL instead of UNION if duplicate data is permissible in result set
		Use LIMIT clause to implement **pagination logic**
			better performance, less network traffic between database & client applications
		
		Don't confuse the Query Optimizer with inaccurate Object Statistics by writing "WHERE city == 'Seattle' and state == 'Washington' "



	
	Window Function 
		https://www.simple-talk.com/sql/t-sql-programming/window-functions-in-sql/
	
	why use a CTE?
		CTEs (common table expressions), temp tables by WITH clauses, it allows you to create something somewhat equivilant to a view that only exists during that transaction.
		Readability is huge when it comes to SQL to ensure its doing the right thing. SQL will almost always tell you an answer, it just may not be to the question you think you’re asking. Ensuring your queries can be reasoned about is critical to ensuring accuracy and CTEs are one great way of accomplishing that.
	
	Foreign Key: 
		one type of CONSTRAINT
		an attribute that references attributes of another table
		the referenced attribute in table 2 must be Primary Key
		values of the foreign key in table 1 must also appear in the referenced attributes in table 2
		
	Constraint:
		Foreign Key
		Not Null
		Attribute-Based CHECK  (check the value of an attribute, can use anything that can follow an WHERE clause)
			checked whenever the attributed is updated/inserted with a new value
		Tuple-Based CHECK (check a tuple/row, can use anything that can follow an WHERE clause)
			checked whenever a tuple is updated/inserted
	
	Assertions: 
		a bollean-valued SQL expressin that must be true at all times (can reference all attributes in a table)
		Must be true when the Assertion is created and remain true thereafter

	Trigger:
		a series of actions that are associated with certain events, (e.g. insertions into a relation), and thare are performed whenever these events arise.
		Event occurs → Test a CONDITION → Take the ACTION associated
	
	View: 
		Virtual View
			tables that are defined by a query over other tables
			
		Materialized View
			views constructed periodically and stored in the database
			need to be recomputed every time one of its base tables changes in any way
				**Index** is a type of Materialized View, sole purpose is to speed up data access
					can think Index as a binary search tree of (Key, Value) pairs; "Key" is a value of an attribute, "Value" is a point to the location of the tuples;
					
	   Why use a view vs. a table?
			provide assess only to the data that specific users are allowed to see
			create custom views to accommodate different needs
			hide the complexity of data retrieval operations

	Temp Table: available within the system while the current session is open
	
	Table Variable: available within a script while the current batch is executing
	
	Derived Table: current statement
	
	Cursor
		a database object that points to a result set. You can use cursor to identify the row to retrieve. (Work with data one row at a time, not the entire relation)
		avoid using cursor whenever possible: slow and take up more system resources
		
	**Execution Plan (Oracle)**
		Can be generated from SQL Plus, SQL Developer, etc.
		store in the memory of the database server
		syntax check → semantic check (you have access to the requested tables, requested columns are valid ones, col def'n, security previliages ...)
		→ check in memoy pool (has this query been run before?) → If yes, use the plan, If not, produce a new plan ( one out of many ) → 
		
	1. Read from 
			inside → out (start with the furthest indented to the right)
			top → down (for those with same indentation)
	2. Check the Plan and think about why optimizer choose this plan
		b. Look for:
			1. **Full Table Scan**
				a. Is it acceptable?
					1. entire table is read up to the High Water Mark (highest block of table that ever had data written to it)
					2. Delete won't release the space (mean # of rows reduces, # of blocks remains the same), Truncate will 
					3. How to lower the HWM? 
						a. ALTER table enable row movement; 
						b. ALTER table shrink space; 
					4. Might be a problem for a Large Table
					5. Are Index available? Create one? Why don't use the existing indices?
			2. **Join methods** (Nested Loop, Hash, Sort Merge, Cartesian; each has Pros & Cons, ), Join Order
				a. **Nested Loop Join**: outer/driving table(usually the smaller of the two sources), inner table (larger); full-scan for the outer; indexed-ranged scan on the inner (index on the FK column that you join on)
					1. Good for joining **smaller** row sources (table != row source, row source might be a filtered table)
					2. Good when the outer source is small and inner source is indexed (small row sources ~ <= 100K rows)
					3. Best for: When you want the **first matched rows back quickest** (may not finish retrieving all the matched rows yet) 
				b. **Hash Join**: smallest row source is chosen to build a hash table in memory and a bitmap; the 2nd row source is hashed and checked against the hash table looking for joins; the bitmap is used as a quick lookup to check if rows are in the hash tabe; Hash table is stored in PGA (Process Global Area) in Memory; 
					1. Good for joining **larger** row sources (scanning a bitmap is faster than a full table)
					2. Needs PGA memory (If PGA is not large enough, the Optimizer may choose Nested Loop Join instead)
				c. **Sort Merge Join**: sort both row sources with the same sort key, then merge the results together; sorting are done in the PGA or on Disk (if PGA is small); 
					1. Not typically what we're looking for! Unless both row sources are small
				d. Cartesian
					1. Avoid it! Result of Poorly written query!
			3. **Index Access Methods**
				a. types:
					1. range scan: read one block at one time
					2. unique scan
					3. full scan: read one block at one time
					4. fast full scan: a little better than full-table scan
					5. skip scan
				b. why is it not using the existing index? 
 
	4. Filters (WHERE clause)
		a. when is it applied (Before any Join or After?)
		b. Optimizer will try to filter rows before performing joins and this is the goal
 
	5. Parallel Operations
		a. Why is it not using Parallel operation? Do I need to provide any hint to the Optimizer?
		b. samples in the Plan:
			1. PX COORDINATOR (PX ~ parallel transaction)
			2. PX BLOCK ITERATOR (breaking the data into smaller pieces)
			3. PX SEND (merge pieces back)
			4. PX RECEIVE
	6. **Partition Processing** (A very Common practice)
		a. Table Partitioning (A single HEAP table divided into partitions, like multiple small tables, if table volume is high)
		b. Eg: Partition the table by Date Range; List Partition, Range Partition, Hash Partition...; 
		c. Optimizer is Partition-Smart
		d. samples in the Plan:
			1. PARTITION LIST SINGLE (reading only one partition)
			2. PARTITION LIST ALL (Optimizer feels it need to access all partition of the table)
		e. When each partition is too small, INSERT performance may be affected but not the SELECT performance
		f. Index can be within or across partitions (Local Partition Index vs. Global Partition Index)
	7. **Dynamic Statistics**
		a. Object Statistics is generated your DBA (# of rows in a table, # of blocks the rows make up, # of distinct values in an index etc.)
		b. **Check** whether Object Statistics is used or not 
		c. Or does the optimizer has to do **Dynamic Sampling** to find Statistics On-the-Fly for your query (slower, may not be good sampling → bad plan)
		d. **Better to make Object Statistics Available and Accurate!! Avoid "dynamic statistics used"**
	8. Cost (IO, CPU, Network Resource etc.)
		a. used to compare different plans for the same query
	9. Eg: why full-table scan? why don't use index? Trying to select large % of the table so a full scan is faster?
	
	c. Adjust parameters of my database?
	d. Adjust the size of memory structure?
	e. Rewrite my query?
	f. Redesign my index?
	

**Misc:**
1. Whenever possible, don’t use a nested queries
2. **Distinct** is same as **Group By**. 
3. Monotone query: Whenever we add tuples to one or more input tables, the answer to the query will not lose any of the tuples
	a. Theorem: If Q is a SELECT-FROM-WHERE query that does not have subqueries, and no aggregates, then it is monotone.
4. Relation, Tuple, Attribute == Table, Row, Column
5. file types: Heap (unsorted), Sequential (sorted in someway)



**Database Management Class at UW**
************************************************************************************************************************************************
**Data Management Concepts**
	* Data models: how to describe real-world data
		–  Relational, XML(eXtensible Markup Language), graph data (RDF: Resource Description Framework)
	* Schema v.s. Data
	* Declarative query language
		–  Say what you want, not how to get it
	* Data independence
		–  Physical independence: Can change how data is stored on disk without maintenance to applications
		–  Logical independence: can change schema w/o affecting apps
	* Query optimizer and compiler
	* Transactions: isolation and atomicity

**Where vs. Having**
	* WHERE condition is applied to individual rows
		–  The rows may or may not contribute to the aggregate
		–  No aggregates allowed here
	* HAVING condition is applied to the entire group
		–  Entire group is returned, or not at all
		–  May use aggregate functions in the group

**Queries that must be nested**
	* Queries with //universal quantifiers// (ALL) or with //negation (Not In, Not Exist ...)//
	* Queries that use aggregates in certain ways
		–  Note: sum(..) and count(*) are NOT monotone, because they do not satisfy set containment
		–  select count(*) from R is not monotone!

**Relational Algebra (How to get the data we want)**
	Key for RA: **PUSH the SELECTIONs DOWN**
	Relational algebra expression is also called the **“logical query plan"**
	A **Physical Query Plan**: a logical query plan annotated with physical implementation details
	
	For each SQL query... many logical plans
	For each logical plan... many physical plans
		e.g. For an inner join: Nest Loop Join, Merge Join, Hash Join

**Query Execution**
	Pipelined Execution (use whenever possible)
	Intermediate Tuple Materialization (for certain operator implementations, not enough memory)
	
**Index**
	Index Organization: B+ trees, Hash Table, Bit Maps, R-trees, Inverted Index
	Clustered (only one) vs. Unclustered (possibly many)
	Primary (over attributes that include the Primary Key) vs. Secondary 
	
	Random reading 1-2% of the file ≈ sequential scanning the entire file;
	
	Each new index slows down updates to table
	
	**Index Selection Problem** is HARD, done by DBA
		Make some attribute K a search key if the WHERE clause contains:
			–  An exact match on K
			–  A range predicate on K
			–  A join on K
		Consider queries in workload in order of importance
		Consider relations accessed by query
			–  No point indexing other relations
		Look at WHERE clause for possible search key
		Try to choose indexes that speed-up multiple queries

**Database Design**
	Starting from scratch, design the database schema: relation, attributes, keys, foreign keys, constraints etc
	
NoSQL
	Motivation: Single Server DBMS is too small for web data
					   Hard to scale out entire functionality of a DBMS
					  NoSQL reduces functionality for easier Scale-Up: simpler data model, simpler transactions
					
	Two approaches:
		partitioning
			fits in main memory; queries spread across machines; easy to write but hard to read
		replication
			easy to read but hard to write

	Data Models:
		Key-Value
		Document: MongoDB, CouchBase, SimpleDB
		Extensible Record: HBase, Cassandra...
		
	JSON:
		self-describing; tree; semi-structured; good for exchange, bad for performance; 
		
	Data Exchange Formats:
		XML: SQL Server
		JSON: CouchBase, MongoDB
		Protobuf: Dremel (BigQuery)
		They differ in how they handle structure: Open vs. Closed, Ordered vs. Unordered
		
	AsterixDB and SQL++
		Index: B-Tree, R-Tree, Keyword
				  cannot index inside of a nested collection
				  
	Conclusion:
		Semistructured data best suited for data exchange
		For quick, ad-hoc data analysis, use a native query language: SQL++, or AQL, or XQuery
		For long term data analysis: spend the time and effort to normalize it, then store in a RDBMS

**Transactions**

	**Transactional Integrity**
		every part of the transaction must be completed before the whole process is done
		finishes with a Commit Or a Rollback
	
		Integrity constraints govern how values in tables are related to each other: 
			Can be enforced by the DBMS (for atomicity and isolation), or ensured by the app
		
	**Guaranteeing Transaction Reliability** (often asked during interview)
		There is a set of properties known by the acronym ACID that guarantee that database transactions are processed reliably and
		concurrently:  https://en.wikipedia.org/wiki/ACID

	**Isolation Levels:** (from most to least stringent)
		Serializable (ACID)
		Repeatable-Read
		Read-Committed
		Read-Uncommitted (Dirty reads)
	
	**ACID:**
	1. Atomicity: A transaction is ATOMIC if all its updates must happen or not at all
 
	2. Consistency: 
		a. App Programmer ensures that: any transaction will bring the database from one valid (satisfying not only all constraints of the database schema, but also the implicit constraints from the DBA) state to another. For instance, all related tables must be updated at the same time you make an update in one table (one reason that NoSQL was invented)
		b. DB ensures that transactions are executed atomically
 
	3. Isolation: the effect of each transaction is as if it were the only transaction running on the system.
 
	4. Durability: It ensures that once a transaction has been committed, it will remain so, even in the event of power loss, crashes, or errors (once a change has been committed, it will be saved somewhere all the time).
				By writing to the disk
	
	 **How to achieve Isolation?** use **Schedulers**
		Serial Schedule: a sequence of transactions that are executed one after another, in sequential order
		Serializable Schedule: a schedule that's equivalent to a Serial Schedule
		Scheduler (Concurrency Control Manager): the module that schedules the transaction’s actions, ensuring serializability
	
	**How to implement Scheduler?**
		Locking (SQLite, SQL Server, DB2)
			To enforce "Conflict-Serializabilty", need "2 Phase Locking":
				In every transaction, all lock requests must procede all unlock requests
				
		Multiversion Concurrency Control (Postgres, Oracle)
		
	**How to avoid Non-recoverable Schedule?**
		Strict 2PL: All locks are held until the transaction commits or aborts
		
	Strict 2PL → Confilct-Serializable & Recoverable
	
	**How to solve Dead Locks?**
		SQL Server: checks periodically for deadlocks and aborts one transaction
		SQLite: No deadlock due to its simple design
		
	**How to avoid Phantom Problem? **
		a tuple that is invisible during part of a transaction execution but not invisible during the entire execution
		HARD.... lock the entire table / lock the index / use predicate locks
		
	**Attention!!!**
		In commercial DBMSs:
	* Default level is often NOT serializable
	* Default level differs between DBMSs
	* Some engines support subset of levels!
	* Serializable may not be exactly ACID
			–  Locking ensures isolation, not atomicity
	* Also, some DBMSs do NOT use locking and
		different isolation levels can lead to different pbs
	* Bottom line: Read the doc for your DBMS!




**BASE ( NoSQL version of ACID)**
	1. Basically available indicates that the system does guarantee availability. (multiple threads can write at the same time for NoSQL; but for SQL, all threads has to merge before they can write in the destination 
	2. Soft state indicates that the state of the system may change over time, even without input.???
	3. Eventual consistency indicates that the system will become consistent over time, given that the system doesn't receive input during that time. (Don't care when a transaction will happen, given knowing it will be there eventually)	
		Main concept: get rid of locks, allow everyone to write, worry about consistency later; writes faster


